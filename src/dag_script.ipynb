{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5120b051-d8c9-412d-9733-878074f7a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f25f1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_files = os.listdir('../schema')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ee44310",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_schemas = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac9bc733",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in schema_files:\n",
    "    opened_file = open('../schema/' + file, 'r')\n",
    "    all_schemas[file] = opened_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9998860",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "            You are a data engineer looking to generate an Airflow pipeline DAG skeleton \n",
    "            without the SQL details\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "363bcce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"\"\"\n",
    "                Generate a cumulative Airflow DAG that transforms \n",
    "                {all_schemas['product.sql']}\n",
    "                into {all_schemas['product_scd_tbl.sql']}\n",
    "                use markdown for output and Postgres for queries\n",
    "                The DAG depends on last season data from players table \n",
    "                and the DAG depends on past is true\n",
    "                All create table statements should include IF NOT EXISTS\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e0d46c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            You are a data engineer looking to generate an Airflow pipeline DAG skeleton \n",
      "            without the SQL details\n",
      "            \n",
      "\n",
      "                Generate a cumulative Airflow DAG that transforms \n",
      "                CREATE TABLE product (\n",
      "  Product_ID INT PRIMARY KEY,\n",
      "  Category_Name VARCHAR(50),\n",
      "  Sub_Category_Name VARCHAR(50),\n",
      "  Brand VARCHAR(50),\n",
      "  Feature_Desc VARCHAR(100)\n",
      ")\n",
      "\n",
      "                into create temp table #product_temp\n",
      "select a.Product_ID as Product_ID_New,\n",
      "case when a.Category_Name <> b.Category_Name then ‘-Category_Name’ else ‘’ end ||\n",
      "case when a.Sub_Category_Name <> b.Sub_Category_Name then ‘-Sub_Category_Name’ else ‘’ end ||\n",
      "case when a.Brand <> b.Brand then ‘-Brand’ else ‘’ end ||\n",
      "case when a.Feature_Desc <> b.Feature_Desc then ‘-Feature_Desc’ else ‘’ end as CHANGED_COLUMN_NEW\n",
      "from Dim_Product a join Stg_Product b\n",
      "on a.Product_ID=b.Product_ID and a.current_flag=’Y’\n",
      "where\n",
      "a.Category_Name <> b.Category_Name or\n",
      "a.Sub_Category_Name <> b.Sub_Category_Name or\n",
      "a.Brand <> b.Brand or\n",
      "a.Feature_Desc <> b.Feature_Desc;\n",
      "\n",
      "                use markdown for output and Postgres for queries\n",
      "                The DAG depends on last season data from players table \n",
      "                and the DAG depends on past is true\n",
      "                All create table statements should include IF NOT EXISTS\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)\n",
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dedb1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "answer = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "239f51be-96f5-4d3e-bb93-bf90275f98b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from airflow import DAG\n",
      "from airflow.operators.postgres_operator import PostgresOperator\n",
      "from datetime import datetime, timedelta\n",
      "\n",
      "default_args = {\n",
      "    'owner': 'airflow',\n",
      "    'depends_on_past': True,\n",
      "    'start_date': datetime(2021, 1, 1),\n",
      "    'email': ['airflow@example.com'],\n",
      "    'email_on_failure': False,\n",
      "    'email_on_retry': False,\n",
      "    'retries': 1,\n",
      "    'retry_delay': timedelta(minutes=5),\n",
      "}\n",
      "\n",
      "dag = DAG(\n",
      "    'product_transformation', default_args=default_args, schedule_interval=timedelta(1))\n",
      "\n",
      "t1 = PostgresOperator(\n",
      "    task_id='create_product_table',\n",
      "    postgres_conn_id='postgres_default',\n",
      "    sql=\"\"\"\n",
      "    CREATE TABLE IF NOT EXISTS product (\n",
      "        Product_ID INT PRIMARY KEY,\n",
      "        Category_Name VARCHAR(50),\n",
      "        Sub_Category_Name VARCHAR(50),\n",
      "        Brand VARCHAR(50),\n",
      "        Feature_Desc VARCHAR(100)\n",
      "    );\n",
      "    \"\"\",\n",
      "    dag=dag)\n",
      "\n",
      "t2 = PostgresOperator(\n",
      "    task_id='create_product_temp_table',\n",
      "    postgres_conn_id='postgres_default',\n",
      "    sql=\"\"\"\n",
      "    CREATE TEMP TABLE IF NOT EXISTS product_temp AS\n",
      "    SELECT \n",
      "        a.Product_ID AS Product_ID_New,\n",
      "        CASE \n",
      "            WHEN a.Category_Name <> b.Category_Name THEN '-Category_Name' \n",
      "            ELSE '' \n",
      "        END ||\n",
      "        CASE \n",
      "            WHEN a.Sub_Category_Name <> b.Sub_Category_Name THEN '-Sub_Category_Name' \n",
      "            ELSE '' \n",
      "        END ||\n",
      "        CASE \n",
      "            WHEN a.Brand <> b.Brand THEN '-Brand' \n",
      "            ELSE '' \n",
      "        END ||\n",
      "        CASE \n",
      "            WHEN a.Feature_Desc <> b.Feature_Desc THEN '-Feature_Desc' \n",
      "            ELSE '' \n",
      "        END AS CHANGED_COLUMN_NEW\n",
      "    FROM \n",
      "        Dim_Product a \n",
      "    JOIN \n",
      "        Stg_Product b\n",
      "    ON \n",
      "        a.Product_ID=b.Product_ID AND a.current_flag='Y'\n",
      "    WHERE\n",
      "        a.Category_Name <> b.Category_Name OR\n",
      "        a.Sub_Category_Name <> b.Sub_Category_Name OR\n",
      "        a.Brand <> b.Brand OR\n",
      "        a.Feature_Desc <> b.Feature_Desc;\n",
      "    \"\"\",\n",
      "    dag=dag)\n",
      "\n",
      "t1 >> t2\n",
      "```\n",
      "\n",
      "This DAG first creates a `product` table if it does not exist. Then it creates a temporary table `product_temp` that contains the transformed data. The `product_temp` table is created by joining `Dim_Product` and `Stg_Product` tables on `Product_ID` and `current_flag='Y'`. The `CHANGED_COLUMN_NEW` column in the `product_temp` table contains the names of the columns that have different values in `Dim_Product` and `Stg_Product` tables. The `product_temp` table is created only if it does not exist. The `t1` task must be completed before the `t2` task can start.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a5f8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('output'):\n",
    "    os.mkdir('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2e78c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = filter(lambda x: x.startswith('python'), answer.split('```'))\n",
    "# Open the file with write permissions\n",
    "with open('output/airflow_dag.py', 'w') as file:\n",
    "    # Write some data to the file\n",
    "    file.write('\\n'.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3693f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
