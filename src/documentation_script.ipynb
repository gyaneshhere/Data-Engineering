{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f4bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b6dd815",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_files = os.listdir('../schema')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391f0ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_schemas = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a74ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in schema_files:\n",
    "    opened_file = open('../schema/' + file, 'r')\n",
    "    all_schemas[file] = opened_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8496e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a data engineer looking to create documentation and example queries for your data sets\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b9023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"\"\"Using cumulative table input schema {all_schemas['product.sql']}\n",
    "                 Generate a pipeline documentation in markdown \n",
    "                    that shows how this is generated from \n",
    "                {all_schemas['product_scd_tbl.sql']}\n",
    "                make sure to include example queries that use the season stats array\n",
    "                make sure to document all columns with column comments\n",
    "                make sure to document all created types as well\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c37130ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a data engineer looking to create documentation and example queries for your data sets\n",
      "Using cumulative table input schema CREATE TABLE product (\n",
      "  Product_ID INT PRIMARY KEY,\n",
      "  Category_Name VARCHAR(50),\n",
      "  Sub_Category_Name VARCHAR(50),\n",
      "  Brand VARCHAR(50),\n",
      "  Feature_Desc VARCHAR(100)\n",
      ")\n",
      "\n",
      "                 Generate a pipeline documentation in markdown \n",
      "                    that shows how this is generated from \n",
      "                create temp table #product_temp\n",
      "select a.Product_ID as Product_ID_New,\n",
      "case when a.Category_Name <> b.Category_Name then ‘-Category_Name’ else ‘’ end ||\n",
      "case when a.Sub_Category_Name <> b.Sub_Category_Name then ‘-Sub_Category_Name’ else ‘’ end ||\n",
      "case when a.Brand <> b.Brand then ‘-Brand’ else ‘’ end ||\n",
      "case when a.Feature_Desc <> b.Feature_Desc then ‘-Feature_Desc’ else ‘’ end as CHANGED_COLUMN_NEW\n",
      "from Dim_Product a join Stg_Product b\n",
      "on a.Product_ID=b.Product_ID and a.current_flag=’Y’\n",
      "where\n",
      "a.Category_Name <> b.Category_Name or\n",
      "a.Sub_Category_Name <> b.Sub_Category_Name or\n",
      "a.Brand <> b.Brand or\n",
      "a.Feature_Desc <> b.Feature_Desc;\n",
      "\n",
      "                make sure to include example queries that use the season stats array\n",
      "                make sure to document all columns with column comments\n",
      "                make sure to document all created types as well\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)\n",
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "462c9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "answer = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be57e39f-e636-404b-af43-6c7d7d50f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Pipeline Documentation\n",
      "\n",
      "This pipeline is designed to generate a temporary table `#product_temp` that identifies the changes in the product details from the staging table `Stg_Product` to the dimension table `Dim_Product`.\n",
      "\n",
      "## Input Schema\n",
      "\n",
      "The input schema for this pipeline is the `product` table with the following columns:\n",
      "\n",
      "- `Product_ID`: An integer that uniquely identifies each product. This is the primary key of the table.\n",
      "- `Category_Name`: A string that represents the category of the product.\n",
      "- `Category_Sub_Name`: A string that represents the sub-category of the product.\n",
      "- `Brand`: A string that represents the brand of the product.\n",
      "- `Feature_Desc`: A string that describes the features of the product.\n",
      "\n",
      "## Pipeline Steps\n",
      "\n",
      "1. The pipeline starts by creating a temporary table `#product_temp` that will store the new product ID and the changed columns.\n",
      "\n",
      "2. It then performs a join operation between the `Dim_Product` and `Stg_Product` tables based on the `Product_ID` and the `current_flag` field.\n",
      "\n",
      "3. The pipeline identifies the columns that have changed by comparing the values in the `Dim_Product` and `Stg_Product` tables. If a change is detected, the column name is appended to the `CHANGED_COLUMN_NEW` field in the `#product_temp` table.\n",
      "\n",
      "## Example Query\n",
      "\n",
      "```sql\n",
      "SELECT Product_ID_New, CHANGED_COLUMN_NEW\n",
      "FROM #product_temp\n",
      "WHERE CHANGED_COLUMN_NEW LIKE '%-Category_Name%'\n",
      "```\n",
      "\n",
      "This query will return all the products that have changes in the `Category_Name` field.\n",
      "\n",
      "## Column Comments\n",
      "\n",
      "- `Product_ID_New`: This is the new product ID after the changes have been made.\n",
      "- `CHANGED_COLUMN_NEW`: This field stores the names of the columns that have changed. If multiple columns have changed, their names are concatenated with a '-'.\n",
      "\n",
      "## Created Types\n",
      "\n",
      "No new types are created in this pipeline. All the types used are standard SQL types.\n",
      "\n",
      "## Note\n",
      "\n",
      "This pipeline assumes that the `current_flag` field in the `Dim_Product` table is used to indicate the current version of the product details. If your implementation is different, you may need to adjust the join condition accordingly.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82bd2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('output'):\n",
    "    os.mkdir('output')\n",
    "# Open the file with write permissions\n",
    "with open('output/documentation.md', 'w') as file:\n",
    "    # Write some data to the file\n",
    "    file.write(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8580680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
